# Fridge Scavenger
This website is designed to allow users to search for recipes they're interested in making at home, as well as input ingredients they have lying around in the fridge in hopes that perhaps they can scrounge up a meal or two. In the (very near) future, users will actually be able to create an account, log in, and save the recipes they're interested in.

## Why?
Surely there are many recipe aggregator websites out there, right? Probably. I'm developing this website purely out of personal interest as a wannabe home chef. I'll honestly probably use it from this point going forward, because if there's anything I don't like about it, I can remove it. If there are any functional components from other websites that I want to use, I can learn how to implement them then do so. It's quite invigorating.

## API Calls

### Spoonacular https://spoonacular.com/food-api/
In the beginning, if you read my commit messages, you'll see that I felt this api was the hottest piece of garbage this side of the Brooklyn Bridge. I'm not from Brooklyn, nor have I ever been there or seen the bridge in question. However, I realized after calling more endpoints, that the specific endpoint I was trying to use was formatted in this weird pseudo-JSON, but all of the other endpoints are actually okay. 

One potential problem I can foresee is that I'm using three different endpoints to generate one page of information, because for some reason all of the aforementoned information is spread out between three endpoints. Makes me sad. In any case, Spoonacular's api works pretty similarly to the FDA's food api. You do an initial search to get a bunch of food items, all with a unique id. That same ID is used to call the other endpoints with more specific recipe data such as directions and nutritional information. Meaning, to get one list of directions from a recipe is ultimately 4 calls to separate endpoints of the same api. The only real issue is that after 150 calls per day, the API stops working. By the time I finish this project the user will be able to use 1500 calls per day, which will cost me like $40 a month, which is fine I guess.

### NewsAPI https://newsapi.org/
I'm using this API to call five of the most recent articles regarding the query, "cooking", to appear on the recipe search page. This was done mostly because I felt the search pages were too bland and sparse before a call was actually made. One issue with this api is that they appear to either have a very limited pool of domains to pull articles from, or no one is writing about cooking in general. Furthermore, I had to add every "terrible" swear word I could think to the api call in order to filter those words out from appearing in the results. Now, however, if you look at the query itself in the code, you'll see a ton of terrible swears. Which, while funny in a way, there's got to be a better way to go about that.

## NextJS
So you've noticed, have you? Well, if you haven't, then this project uses NextJS, which is somewhat like a backend React framework, if that makes sense. To me, it's just a much lighter, much more user-friendly NodeJS. One of the problems I would have with my other React projects is the load times of some functions that would call api endpoints and map the data across the screen. With NextJS, all of the processing is done on the server-side, so the client gets near-instant loading. One of the best features of NextJS is the dynamic page creation using the "p/[id].js" file system. The recipes you pull up on the website are generated dynamically using the id of the page itself to call the api. If you don't have a recipe pulled up, the recipe page does not exist, in theory. This should ideally reduce server load and keep the site running fairly smoothly. Unless this project explodes and really takes off (popularity), I don't anticipate many/any users, so the server load shouldn't be an issue regardless, but the smoother the better.

## Firebase! No, Express! No, Firebase!
For the backend, I've pivoted back and forth between using Firebase and using an express server a couple of times. The reason being is that nothing is as straight forward as it should be in NextJS, and for some strange reason, Webpack hates pretty much everything you try to add to it. Configuring webpack and troubleshooting has become so time intensive that it would actually take less time to stop trying to learn a new technology and just sticking with express. You're probably wondering how "this time will be different" with Express. This time, with the assistance of Backend Guru Christopher Kemp, I'm going to have a completely separate file system for connecting my database to an express server, instead of just trying to cram it into NextJS haphazardly. The only forseeable problem is that the api server has to now be active at all times, and the second there is even the slightest hiccup, all user functionality will cease.

## No Comments
After really thinking about it, I've never seen comments on a recipe website and thought, "Man, that really added a lot to this experience". So the comment system will be scraped. You might be thinking, "Oh, you just don't want to code that feature in", and you would be right, but I'd still maintain that a comment section is really unnecessary. Could I add it in the future? Absolutely. Will I? Maybe.

## Backend Database
The backend for this project is ultimately a postgres database being connected to with an express server that actually runs from a port (5423 or thereabouts) on my laptop. It doesn't have official hosting, so that basically means the second I close the terminal running the server, all login and otherwise database-related functionality will throw massive errors or 404s at the user. This isn't ideal, so I'll have to attach the express server to an Amazon EC2 instance in the future. On that note, the postgres database itself is also located locally, on this device (my laptop). Originally, I was dead-set on using Amazon's cloud database system, but kept getting unusual errors when trying to connect to it with express, so for the sake of time and ease, my local postgres configuration was used instead.

## Password Encryption
Password encryption is done through the bcrypt npm module. This module takes a password, hashes it x times (10 in this instance), then stores the hashed value in the database. Meaning, I, the developer, can't see anyone's password at any time. When looking at my database of users, I see a random mix of characters in the "password" column. When users login, the module compares the non-hashed password with the user's typed value to login. I can't be 100% sure that this is secure with no security holes whatsoever, so I would still recommend that users just set their passwords to "password".
